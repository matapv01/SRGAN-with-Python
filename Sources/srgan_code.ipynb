{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T10:46:16.232720Z",
     "iopub.status.busy": "2024-10-28T10:46:16.232343Z",
     "iopub.status.idle": "2024-10-28T10:49:03.531330Z",
     "shell.execute_reply": "2024-10-28T10:49:03.530427Z",
     "shell.execute_reply.started": "2024-10-28T10:46:16.232681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_dir = \"/kaggle/input/augmented-hardhat-vest-dataset/DIV2K_train_HR/\"  \n",
    "output_dir = '/kaggle/working/'\n",
    "os.makedirs(output_dir + \"hr_images/\", exist_ok=True)\n",
    "os.makedirs(output_dir + \"lr_images/\", exist_ok=True)\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n",
    "\n",
    "for img in os.listdir(train_dir):\n",
    "    if is_image_file(img):\n",
    "        img_array = cv2.imread(train_dir + img)\n",
    "        img_array = cv2.resize(img_array, (128, 128)) # bicubic interpolation\n",
    "        lr_img_array = cv2.resize(img_array, (32, 32)) # bicubic interpolation\n",
    "        cv2.imwrite(output_dir + \"hr_images/\" + img, img_array)\n",
    "        cv2.imwrite(output_dir + \"lr_images/\" + img, lr_img_array)\n",
    "\n",
    "lr_list = os.listdir(output_dir + \"lr_images\")\n",
    "hr_list = os.listdir(output_dir + \"hr_images\")\n",
    "\n",
    "lr_images = []\n",
    "hr_images = []\n",
    "for lr_img, hr_img in zip(lr_list, hr_list):\n",
    "    img_lr = cv2.imread(output_dir + \"lr_images/\" + lr_img)\n",
    "    img_lr = cv2.cvtColor(img_lr, cv2.COLOR_BGR2RGB)\n",
    "    img_hr = cv2.imread(output_dir + \"hr_images/\" + hr_img)\n",
    "    img_hr = cv2.cvtColor(img_hr, cv2.COLOR_BGR2RGB) # BGR to RGB\n",
    "    lr_images.append(img_lr)\n",
    "    hr_images.append(img_hr)\n",
    "\n",
    "lr_images = np.array(lr_images)\n",
    "hr_images = np.array(hr_images)\n",
    "\n",
    "lr_images = lr_images / 255. # Devide to float\n",
    "hr_images = hr_images / 255. # RGB value: 8 bit\n",
    "\n",
    "lr_train, lr_test, hr_train, hr_test = train_test_split(lr_images, hr_images, test_size=0.33, random_state=42)\n",
    "\n",
    "# array numpy: N H W C -> tensor pytorch: N C H W\n",
    "lr_train = torch.from_numpy(lr_train).permute(0, 3, 1, 2).float()\n",
    "hr_train = torch.from_numpy(hr_train).permute(0, 3, 1, 2).float()\n",
    "lr_test = torch.from_numpy(lr_test).permute(0, 3, 1, 2).float()\n",
    "hr_test = torch.from_numpy(hr_test).permute(0, 3, 1, 2).float()\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64) # Normalize data based on the mean and variance of a mini-batch -> faster convergence\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.prelu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual # residual connection\n",
    "        return out\n",
    "\n",
    "\n",
    "class UpscaleBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UpscaleBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(64, 256, kernel_size=3, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(2) # Upsampling\n",
    "        self.prelu = nn.PReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.pixel_shuffle(out)\n",
    "        out = self.prelu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_res_blocks=16):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=4)\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.res_blocks = nn.Sequential(*[ResBlock() for _ in range(num_res_blocks)]) # * unpacking\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(64)\n",
    "        self.upscale1 = UpscaleBlock()\n",
    "        self.upscale2 = UpscaleBlock()\n",
    "        self.conv3 = nn.Conv2d(64, 3, kernel_size=9, padding=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.conv1(x)\n",
    "        out1 = self.prelu(out1)\n",
    "        out = self.res_blocks(out1)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn(out)\n",
    "        out += out1\n",
    "        out = self.upscale1(out)\n",
    "        out = self.upscale2(out)\n",
    "        out = self.conv3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class DiscriminatorBlock(nn.Module):\n",
    "    def __init__(self, in_filters, out_filters, strides=1, bn=True): \n",
    "        super(DiscriminatorBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=strides, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(out_filters) if bn else None # bn=True -> batch normalization\n",
    "        self.lrelu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        if self.bn:\n",
    "            out = self.bn(out)\n",
    "        out = self.lrelu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.block1 = DiscriminatorBlock(3, 64, bn=False)\n",
    "        self.block2 = DiscriminatorBlock(64, 64, strides=2)\n",
    "        self.block3 = DiscriminatorBlock(64, 128)\n",
    "        self.block4 = DiscriminatorBlock(128, 128, strides=2)\n",
    "        self.block5 = DiscriminatorBlock(128, 256)\n",
    "        self.block6 = DiscriminatorBlock(256, 256, strides=2)\n",
    "        self.block7 = DiscriminatorBlock(256, 512)\n",
    "        self.block8 = DiscriminatorBlock(512, 512, strides=2)\n",
    "\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((6, 6)) # pooling: downsample feature map (average pixel value) -> 6x6\n",
    "        self.flatten = nn.Flatten() # C_tensor=1 to connect to fully-connected layers (dense layers)\n",
    "        self.linear1 = nn.Linear(512 * 6 * 6, 1024) # fully connected layer (dense layer) with 1024 neuron\n",
    "        self.lrelu = nn.LeakyReLU(0.2) \n",
    "        self.linear2 = nn.Linear(1024, 1) # 1 neuron\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block1(x)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.block4(out)\n",
    "        out = self.block5(out)\n",
    "        out = self.block6(out)\n",
    "        out = self.block7(out)\n",
    "        out = self.block8(out)\n",
    "        out = self.adaptive_pool(out)\n",
    "        out = self.flatten(out)\n",
    "\n",
    "        out = self.linear1(out)\n",
    "        out = self.lrelu(out)\n",
    "        out = self.linear2(out)\n",
    "\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class VGGFeatureExtractor(nn.Module):\n",
    "    def __init__(self, vgg_weights_path):\n",
    "        super(VGGFeatureExtractor, self).__init__()\n",
    "        vgg19 = models.vgg19()\n",
    "        if vgg_weights_path:\n",
    "            state_dict = torch.load(vgg_weights_path)\n",
    "            vgg19.load_state_dict(state_dict, strict=False)  \n",
    "\n",
    "\n",
    "        self.features = nn.Sequential(*list(vgg19.features.children())[:11]) \n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False # not update parameters\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = Generator().to(device) # move weights and tensors to device (cpu or cuda)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "\n",
    "vgg_weights_path = '/kaggle/input/vgg19-weights-pth/vgg19-dcbb9e9d.pth' \n",
    "vgg = VGGFeatureExtractor(vgg_weights_path).to(device)\n",
    "\n",
    "\n",
    "criterion_gan = nn.BCEWithLogitsLoss() # D loss (minimize  binary cross-entropy loss with sigmoid)\n",
    "criterion_content = nn.MSELoss() # G loss (minimize MSE loss)\n",
    "\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.0001) # Adam optimizer with learning rate = 0.0001\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0001)\n",
    "\n",
    "batch_size = 8 \n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    for i in tqdm(range(0, len(lr_train), batch_size)):\n",
    "        lr_batch = lr_train[i:i + batch_size].to(device)\n",
    "        hr_batch = hr_train[i:i + batch_size].to(device)\n",
    "\n",
    "        optimizer_d.zero_grad() # reset gradient of weights and biases (= 0) in Discriminator\n",
    "        fake_images = generator(lr_batch)\n",
    "        real_labels = torch.ones(lr_batch.size(0), 1).to(device) # label HR tensor Nx1 = 1\n",
    "        fake_labels = torch.zeros(lr_batch.size(0), 1).to(device) # label SR tensor Nx1 = 0\n",
    "\n",
    "        d_loss_real = criterion_gan(discriminator(hr_batch), real_labels)\n",
    "        d_loss_fake = criterion_gan(discriminator(fake_images.detach()), fake_labels) # detach SR from computation graph\n",
    "        d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "        d_loss.backward() # backpropagation (calculate gradient)\n",
    "        optimizer_d.step() # update weights and biases of D\n",
    "\n",
    "        optimizer_g.zero_grad() # reset gradient of weights and biases (= 0) in Generator\n",
    "        g_loss_gan = criterion_gan(discriminator(fake_images), real_labels)\n",
    "        vgg_features_real = vgg(hr_batch)\n",
    "        vgg_features_fake = vgg(fake_images)\n",
    "        g_loss_content = criterion_content(vgg_features_fake, vgg_features_real)\n",
    "        g_loss = 0.001 * g_loss_gan + g_loss_content\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        g_losses.append(g_loss.item()) # .item(): get scalar (number)\n",
    "        d_losses.append(d_loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, G Loss: {np.mean(g_losses):.4f}, D Loss: {np.mean(d_losses):.4f}\")\n",
    "torch.save(generator.state_dict(), \"final_generator.pt\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T10:49:03.534030Z",
     "iopub.status.busy": "2024-10-28T10:49:03.533479Z",
     "iopub.status.idle": "2024-10-28T10:49:04.140409Z",
     "shell.execute_reply": "2024-10-28T10:49:04.139499Z",
     "shell.execute_reply.started": "2024-10-28T10:49:03.533985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "generator.load_state_dict(torch.load(\"final_generator.pt\"))\n",
    "generator.eval() # change generator to eval mode (turn off BN and Dropout)\n",
    "\n",
    "ix = np.random.randint(0, len(lr_test), 1) # random int num in range\n",
    "lr_image = lr_test[ix].to(device)\n",
    "hr_image = hr_test[ix].to(device)\n",
    "\n",
    "with torch.no_grad(): # off gradient calculation\n",
    "    sr_image = generator(lr_image)\n",
    "\n",
    "vgg_features_real = vgg(hr_image)\n",
    "vgg_features_fake = vgg(sr_image)\n",
    "content_loss = criterion_content(vgg_features_fake, vgg_features_real).item()  \n",
    "\n",
    "lr_image = lr_image.cpu().squeeze(0).permute(1, 2, 0).numpy() \n",
    "hr_image = hr_image.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
    "sr_image = sr_image.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
    "# GPU -> CPU, delete N(=1), C H W -> H W C -> numpy (to use matplotlib imshow)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"LR Image\")\n",
    "plt.imshow(lr_image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"SR Image\")\n",
    "plt.imshow(sr_image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"HR Image\")\n",
    "plt.imshow(hr_image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"Content Loss for SR Image: {content_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5918130,
     "sourceId": 9681979,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5919756,
     "sourceId": 9684225,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5948130,
     "sourceId": 9721787,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
